# Import necessary libraries
import tensorflow as tf
from tensorflow.keras import layers, models
import numpy as np
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
from google.colab import files

# Define the Generator model
def build_generator(latent_dim):
    model = models.Sequential()
    model.add(layers.Dense(128 * 7 * 7, input_dim=latent_dim))
    model.add(layers.Reshape((7, 7, 128)))
    model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))
    model.add(layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same'))
    model.add(layers.Conv2DTranspose(1, (7, 7), activation='sigmoid', padding='same'))
    return model

# Define the Discriminator model
def build_discriminator(img_shape):
    model = models.Sequential()
    model.add(layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same', input_shape=img_shape))
    model.add(layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same'))
    model.add(layers.Flatten())
    model.add(layers.Dense(1, activation='sigmoid'))
    return model

# Define the GAN model
def build_gan(generator, discriminator):
    discriminator.trainable = False
    model = models.Sequential()
    model.add(generator)
    model.add(discriminator)
    return model

# Load and preprocess your dataset
# Assume you have your images in a folder named "images"
# You may need to upload your images to Google Colab first
uploaded = files.upload()

# Preprocess and normalize images
images = []
for img_path in uploaded.keys():
    img = image.load_img(img_path, target_size=(28, 28), color_mode="grayscale")
    img = image.img_to_array(img)
    img = img / 255.0  # Normalize pixel values to the range [0, 1]
    images.append(img)

# Convert the list of images to a NumPy array
images = np.array(images)

# Set up GAN parameters
latent_dim = 100
img_shape = (28, 28, 1)

# Build and compile the discriminator
discriminator = build_discriminator(img_shape)
discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Build the generator
generator = build_generator(latent_dim)

# Build and compile the GAN
discriminator.trainable = False
gan = build_gan(generator, discriminator)
gan.compile(loss='binary_crossentropy', optimizer='adam')

# Train the GAN
epochs = 10000
batch_size = 64

# Adversarial ground truths
valid = np.ones((batch_size, 1))
fake = np.zeros((batch_size, 1))

for epoch in range(epochs):

    # Select a random batch of images
    idx = np.random.randint(0, images.shape[0], batch_size)
    imgs = images[idx]

    # Generate a batch of fake images
    noise = np.random.normal(0, 1, (batch_size, latent_dim))
    gen_imgs = generator.predict(noise)

    # Train the discriminator
    d_loss_real = discriminator.train_on_batch(imgs, valid)
    d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)
    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

    # Train the generator
    noise = np.random.normal(0, 1, (batch_size, latent_dim))
    g_loss = gan.train_on_batch(noise, valid)

    # Print progress and save generated images at checkpoints
    if epoch % 100 == 0:
        print(f"{epoch} [D loss: {d_loss[0]} | D accuracy: {100 * d_loss[1]}] [G loss: {g_loss}]")

        # Save generated images
        if epoch % 1000 == 0:
            # Generate 5 random images
            generated_images = generator.predict(np.random.normal(0, 1, (5, latent_dim)))

            # Display generated images
            for i in range(generated_images.shape[0]):
                plt.imshow(generated_images[i, :, :, 0], cmap='gray')
                plt.axis('off')
                plt.show()






------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


# ... (previous code remains the same)

# Train the GAN
# (Same training loop as before)

# Save the trained generator model
generator.save('01010110100011000.h5')
print("Generator model saved.")

# Generate and display some images using the trained generator
num_images_to_generate = 5
noise_for_generation = np.random.normal(0, 1, (num_images_to_generate, latent_dim))
generated_images = generator.predict(noise_for_generation)

for i in range(generated_images.shape[0]):
    plt.imshow(generated_images[i, :, :, 0], cmap='gray')
    plt.axis('off')
    plt.show()


------------------------------------------------------------------------------------------------------------------------------------------------------------------------------



# Load the saved generator model
from tensorflow.keras.models import load_model

generator = load_model('01010110100011000.h5')  # Replace 'generator_model.h5' with your model path

# Generate and display some images using the loaded generator
num_images_to_generate = 5
latent_dim = 100  # Assuming the latent dimension used during training
noise_for_generation = np.random.normal(0, 1, (num_images_to_generate, latent_dim))
generated_images = generator.predict(noise_for_generation)

for i in range(generated_images.shape[0]):
    plt.imshow(generated_images[i, :, :, 0], cmap='gray')
    plt.axis('off')
    plt.show()

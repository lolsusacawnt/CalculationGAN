import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Conv2D, Conv2DTranspose
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import load_img, img_to_array

--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------




# Define the path to your images directory
images_directory = '/content/bro'

# Function to load and preprocess images
def load_images(directory):
    images = []
    for filename in os.listdir(directory):
        if filename.endswith('.jpg') or filename.endswith('.png'):
            img = load_img(os.path.join(directory, filename), target_size=(64, 64))  # Change target size as needed
            img_array = img_to_array(img)
            images.append(img_array)
    return np.asarray(images)

# Load and preprocess images
images = load_images(images_directory)
images = (images.astype(np.float32) - 127.5) / 127.5  # Normalize images to [-1, 1]

--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


# Generator model
def build_generator():
    model = Sequential()
    model.add(Dense(256, input_dim=100))
    model.add(Dense(512))
    model.add(Dense(1024))
    model.add(Dense(64 * 64 * 3, activation='tanh'))  # Output layer
    model.add(Reshape((64, 64, 3)))
    return model

# Discriminator model
def build_discriminator():
    model = Sequential()
    model.add(Flatten(input_shape=(64, 64, 3)))
    model.add(Dense(1024))
    model.add(Dense(512))
    model.add(Dense(256))
    model.add(Dense(1, activation='sigmoid'))
    return model

# Create instances of the models
generator = build_generator()
discriminator = build_discriminator()


------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

# Compile the discriminator
discriminator.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002), metrics=['accuracy'])

# Combined GAN model (stacking generator and discriminator)
z = Input(shape=(100,))
img = generator(z)
discriminator.trainable = False  # Freeze discriminator during GAN training
validity = discriminator(img)
gan = Model(z, validity)
gan.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002))


------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


# Function to train GAN
def train_gan(epochs, batch_size, sample_interval):
    half_batch = batch_size // 2

    for epoch in range(epochs):
        # Select a random half batch of images
        idx = np.random.randint(0, images.shape[0], half_batch)
        imgs = images[idx]

        # Generate a half batch of fake images
        noise = np.random.normal(0, 1, (half_batch, 100))
        gen_imgs = generator.predict(noise)

        # Train the discriminator
        d_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))
        d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))
        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

        # Train the generator (via the GAN model)
        noise = np.random.normal(0, 1, (batch_size, 100))
        valid_y = np.array([1] * batch_size)
        g_loss = gan.train_on_batch(noise, valid_y)

        # Print the progress
        if epoch % sample_interval == 0:
            print(f"Epoch {epoch}, [D loss: {d_loss[0]}, acc.: {100 * d_loss[1]}%], [G loss: {g_loss}]")
            # Optionally, save generated images
            save_images(epoch)

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------



# Function to save generated images
def save_images(epoch):
    r, c = 5, 5  # Number of rows and columns of generated images
    noise = np.random.normal(0, 1, (r * c, 100))
    gen_imgs = generator.predict(noise)
    gen_imgs = 0.5 * gen_imgs + 0.5  # Rescale generated images to [0, 1]

    fig, axs = plt.subplots(r, c)
    idx = 0
    for i in range(r):
        for j in range(c):
            axs[i,j].imshow(gen_imgs[idx])
            axs[i,j].axis('off')
            idx += 1
    fig.savefig(f"gan_images/gan_output_epoch_{epoch}.png")  # Save the generated images
    plt.close()


-=-------------------------------------------------------------------------=---------------------------------------


# Set hyperparameters and train the GAN
epochs = 20000  # Number of epochs
batch_size = 32  # Batch size
sample_interval = 1000  # Interval for displaying the progress

# Create a directory to save generated images
os.makedirs("gan_images", exist_ok=True)

# Train the GAN
train_gan(epochs, batch_size, sample_interval)

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# Save the generator and discriminator models
generator.save('generator_model.h5')
discriminator.save('discriminator_model.h5')

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

# Load the generator and discriminator models
loaded_generator = tf.keras.models.load_model('generator_model.h5')
loaded_discriminator = tf.keras.models.load_model('discriminator_model.h5')

# Function to generate images using the loaded generator
def generate_images(num_images):
    noise = np.random.normal(0, 1, (num_images, 100))
    generated_images = loaded_generator.predict(noise)
    generated_images = 0.5 * generated_images + 0.5  # Rescale generated images to [0, 1]
    return generated_images

# Generate new images using the loaded generator
num_images_to_generate = 111  # Change as needed
new_images = generate_images(num_images_to_generate)

# Display or save the generated images
for i, img in enumerate(new_images):
    plt.imshow(img)
    plt.axis('off')
    plt.savefig(f"generated_image_{i}.png")  # Save each generated image
    plt.show()
